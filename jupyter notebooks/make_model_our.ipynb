{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, MaxPool2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import json, sys, random, os\n",
    "import PIL\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,ZeroPadding2D\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from PIL import Image, ImageDraw \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "import time  \n",
    "import math\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.applications.vgg16 import decode_predictions\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18870 images belonging to 8 classes.\n",
      "Found 4724 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        r\"E:\\programming\\bachelor_project\\kristinasandmarine_backup\\train\",\n",
    "        target_size=(224, 224),\n",
    "        batch_size = 128,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        r\"E:\\programming\\bachelor_project\\kristinasandmarine_backup\\test\",\n",
    "        target_size=(224, 224),\n",
    "        batch_size = 128,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 109, 109, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 52, 52, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 86528)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               44302848  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 4104      \n",
      "=================================================================\n",
      "Total params: 44,400,200\n",
      "Trainable params: 44,400,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn = Sequential() #Choosing sequential model.\n",
    "cnn.add(Conv2D(filters=32, kernel_size=3, activation=\"relu\",input_shape=(224,224,3))) #Adding convolution layer\n",
    "cnn.add(MaxPool2D(pool_size=2, strides=2))\n",
    "cnn.add(Conv2D(filters= 64, kernel_size=3, activation= \"relu\"))\n",
    "cnn.add(MaxPool2D(pool_size=2, strides=2))\n",
    "cnn.add(Conv2D(filters= 128, kernel_size=3, activation= \"relu\"))\n",
    "cnn.add(MaxPool2D(pool_size=2, strides=2))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(units=512,activation=\"relu\"))\n",
    "cnn.add(Dense(units=8,activation=\"softmax\"))\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "148/148 [==============================] - 1379s 9s/step - loss: 0.9894 - accuracy: 0.7272 - val_loss: 0.3378 - val_accuracy: 0.9060\n",
      "Epoch 2/20\n",
      "148/148 [==============================] - 1315s 9s/step - loss: 0.2986 - accuracy: 0.8944 - val_loss: 0.2473 - val_accuracy: 0.9128\n",
      "Epoch 3/20\n",
      "148/148 [==============================] - 1320s 9s/step - loss: 0.1901 - accuracy: 0.9332 - val_loss: 0.1847 - val_accuracy: 0.9409\n",
      "Epoch 4/20\n",
      "148/148 [==============================] - 1290s 9s/step - loss: 0.1835 - accuracy: 0.9401 - val_loss: 0.1388 - val_accuracy: 0.9610\n",
      "Epoch 5/20\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.1336 - accuracy: 0.9558"
     ]
    }
   ],
   "source": [
    "history= cnn.fit(x=training_set,validation_data=test_set,epochs=20)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ce0e62306dd6a5716965d4519ada776f947e6dfc145b604b11307c10277ef29"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
